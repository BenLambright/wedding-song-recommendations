{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfeb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cac0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection dependentcies\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abfafcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/29 17:28:34 WARN Utils: Your hostname, Bens-MacBook-Air-7.local, resolves to a loopback address: 127.0.0.1; using 172.20.10.3 instead (on interface en0)\n",
      "25/11/29 17:28:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/29 17:28:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Preprocessing\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3f2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = spark.read.csv(\"subset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe10536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|               title|               album|language_id|\n",
      "+--------------------+--------------------+-----------+\n",
      "|Chantaje (feat. M...|           El Dorado|        1.0|\n",
      "|Vente Pa' Ca (fea...|Vente Pa' Ca (fea...|        1.0|\n",
      "|Reggaetón Lento (...|        Primera Cita|        1.0|\n",
      "|              Safari|             Energía|        1.0|\n",
      "|         Shaky Shaky|         Shaky Shaky|        0.0|\n",
      "+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# for now we'll do the language detection first, but this won't work at scale so we'll have to do somethign else later\n",
    "languages = [Language.ENGLISH, Language.SPANISH]\n",
    "pattern = r\"\\s*[\\(\\[].*?[\\)\\]]\"\n",
    "\n",
    "def detect_language_udf(title, album):\n",
    "    cleaned_title = re.sub(pattern, \"\", title, flags=re.IGNORECASE).strip()\n",
    "    cleaned_album = re.sub(pattern, \"\", album, flags=re.IGNORECASE).strip()\n",
    "    combined_text = f\"{cleaned_title} {cleaned_album}\"\n",
    "    if not combined_text.strip():\n",
    "        return 0.0  # return 0.0 for empty strings to just guess - we might want to make this more sophisticated later\n",
    "\n",
    "    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "    language = detector.detect_language_of(combined_text)\n",
    "    return float(languages.index(language))\n",
    "\n",
    "detect_language = F.udf(detect_language_udf, FloatType())\n",
    "\n",
    "df_with_lang = df.withColumn(\"language_id\", detect_language(F.col(\"title\"), F.col(\"album\")))\n",
    "\n",
    "new_df = df_with_lang.select(\"title\", \"album\", \"language_id\")\n",
    "new_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5524854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+-------------+--------+----------+-----------+--------+------------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+\n",
      "|Unnamed: 0|               title|rank|        trend| streams|popularity|duration_ms|explicit|release_date|af_danceability|af_energy|af_key|af_loudness|af_mode|af_speechiness|af_acousticness|af_instrumentalness|af_liveness|af_valence|af_tempo|af_time_signature|\n",
      "+----------+--------------------+----+-------------+--------+----------+-----------+--------+------------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+\n",
      "|         0|Chantaje (feat. M...|   1|SAME_POSITION|253019.0|      78.0|   195840.0|   false|  2017-05-26|          0.852|    0.773|   8.0|     -2.921|    0.0|        0.0776|          0.187|            3.05E-5|      0.159|     0.907| 102.034|              4.0|\n",
      "|         1|Vente Pa' Ca (fea...|   2|      MOVE_UP|223988.0|      72.0|   259195.0|   false|  2016-09-22|          0.663|     0.92|  11.0|      -4.07|    0.0|         0.226|        0.00431|            1.69E-5|      0.101|     0.533|  99.935|              4.0|\n",
      "|         2|Reggaetón Lento (...|   3|    MOVE_DOWN|210943.0|      73.0|   222560.0|   false|  2016-08-26|          0.761|    0.838|   4.0|     -3.073|    0.0|        0.0502|            0.4|                0.0|      0.176|      0.71|  93.974|              4.0|\n",
      "|         3|              Safari|   4|SAME_POSITION|173865.0|       0.0|   205600.0|   false|  2016-06-24|          0.508|    0.687|   0.0|     -4.361|    1.0|         0.326|          0.551|            3.41E-6|      0.126|     0.555| 180.044|              4.0|\n",
      "|         4|         Shaky Shaky|   5|      MOVE_UP|153956.0|       0.0|   234320.0|   false|  2016-04-08|          0.899|    0.626|   6.0|     -4.228|    0.0|         0.292|          0.076|                0.0|     0.0631|     0.873|  88.007|              4.0|\n",
      "+----------+--------------------+----+-------------+--------+----------+-----------+--------+------------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# remove the following columns: urls, track_id, data, available markets, id, and date\n",
    "# also remove artist, album, region, and name because they are strings not worth embedding for now\n",
    "# also remove chart because I don't think there are enough charts for this to be relevant\n",
    "# finally, remove index because dataframes already have an index\n",
    "columns_to_remove = [\n",
    "    \"urls\", \"track_id\", \"data\", \"available_markets\", \"id\", \"url\", \"date\",\n",
    "    \"artist\", \"album\", \"region\", \"name\", \"chart\"\n",
    "]\n",
    "df = df.drop(*columns_to_remove)\n",
    "\n",
    "# df = df.drop(*columns_to_remove)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4fde40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates by checking to see if any titles match\n",
    "df = df.dropDuplicates([\"title\"])\n",
    "df = df.drop(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e7f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/29 17:28:39 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------------+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|Unnamed: 0|rank|        trend|streams|popularity|duration_ms|explicit|af_danceability|af_energy|af_key|af_loudness|af_mode|af_speechiness|af_acousticness|af_instrumentalness|af_liveness|af_valence|af_tempo|af_time_signature|  date|\n",
      "+----------+----+-------------+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|        34|  35|      MOVE_UP|56170.0|      80.0|   236001.0|   false|          0.666|     0.83|   0.0|     -5.715|    1.0|        0.0751|         0.0123|                0.0|      0.191|     0.702|  113.03|              4.0|2016.0|\n",
      "|        33|  34|    MOVE_DOWN|58801.0|      80.0|   225983.0|   false|          0.818|    0.803|   1.0|     -4.282|    1.0|        0.0797|          0.034|                0.0|      0.153|     0.632|  106.97|              4.0|2016.0|\n",
      "|       114| 114|SAME_POSITION|21584.0|      59.0|   206760.0|   false|          0.849|    0.759|   9.0|     -6.232|    0.0|        0.0304|         0.0951|            1.21E-4|      0.127|     0.948| 110.983|              4.0|2017.0|\n",
      "|       163| 163|SAME_POSITION|16865.0|       0.0|   167053.0|   false|          0.731|    0.863|   2.0|     -5.331|    1.0|        0.0377|          0.125|                0.0|      0.195|     0.963| 107.992|              4.0|2016.0|\n",
      "|       141| 141|    MOVE_DOWN|18810.0|      40.0|   237290.0|   false|          0.745|    0.875|   0.0|     -4.231|    1.0|        0.0444|         0.0659|             1.5E-6|      0.366|     0.728|  88.007|              4.0|2016.0|\n",
      "+----------+----+-------------+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# convert the date columns into a float representing the year\n",
    "def date_to_year(date):\n",
    "    try:\n",
    "        return float(date.year)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "date_to_year_udf = F.udf(date_to_year, FloatType())\n",
    "df = df.withColumn(\"date\", date_to_year_udf(F.col(\"release_date\")))\n",
    "df = df.drop(\"release_date\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcfa58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|Unnamed: 0|rank|trend|streams|popularity|duration_ms|explicit|af_danceability|af_energy|af_key|af_loudness|af_mode|af_speechiness|af_acousticness|af_instrumentalness|af_liveness|af_valence|af_tempo|af_time_signature|  date|\n",
      "+----------+----+-----+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|        34|  35|  2.0|56170.0|      80.0|   236001.0|   false|          0.666|     0.83|   0.0|     -5.715|    1.0|        0.0751|         0.0123|                0.0|      0.191|     0.702|  113.03|              4.0|2016.0|\n",
      "|        33|  34|  0.0|58801.0|      80.0|   225983.0|   false|          0.818|    0.803|   1.0|     -4.282|    1.0|        0.0797|          0.034|                0.0|      0.153|     0.632|  106.97|              4.0|2016.0|\n",
      "|       114| 114|  1.0|21584.0|      59.0|   206760.0|   false|          0.849|    0.759|   9.0|     -6.232|    0.0|        0.0304|         0.0951|            1.21E-4|      0.127|     0.948| 110.983|              4.0|2017.0|\n",
      "|       163| 163|  1.0|16865.0|       0.0|   167053.0|   false|          0.731|    0.863|   2.0|     -5.331|    1.0|        0.0377|          0.125|                0.0|      0.195|     0.963| 107.992|              4.0|2016.0|\n",
      "|       141| 141|  0.0|18810.0|      40.0|   237290.0|   false|          0.745|    0.875|   0.0|     -4.231|    1.0|        0.0444|         0.0659|             1.5E-6|      0.366|     0.728|  88.007|              4.0|2016.0|\n",
      "+----------+----+-----+-------+----------+-----------+--------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# convert the trend column into a scale from 0-2\n",
    "def trend_to_scale(trend):\n",
    "    if trend == \"MOVE_UP\":\n",
    "        return 2.0\n",
    "    elif trend == \"MOVE_DOWN\":\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "trend_to_scale_udf = F.udf(trend_to_scale, FloatType())\n",
    "df = df.withColumn(\"trend\", trend_to_scale_udf(F.col(\"trend\")))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d997fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|Unnamed: 0|rank|trend|streams|popularity|duration_ms|af_danceability|af_energy|af_key|af_loudness|af_mode|af_speechiness|af_acousticness|af_instrumentalness|af_liveness|af_valence|af_tempo|af_time_signature|  date|\n",
      "+----------+----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|        34|  35|  2.0|56170.0|      80.0|   236001.0|          0.666|     0.83|   0.0|     -5.715|    1.0|        0.0751|         0.0123|                0.0|      0.191|     0.702|  113.03|              4.0|2016.0|\n",
      "|        33|  34|  0.0|58801.0|      80.0|   225983.0|          0.818|    0.803|   1.0|     -4.282|    1.0|        0.0797|          0.034|                0.0|      0.153|     0.632|  106.97|              4.0|2016.0|\n",
      "|       114| 114|  1.0|21584.0|      59.0|   206760.0|          0.849|    0.759|   9.0|     -6.232|    0.0|        0.0304|         0.0951|            1.21E-4|      0.127|     0.948| 110.983|              4.0|2017.0|\n",
      "|       163| 163|  1.0|16865.0|       0.0|   167053.0|          0.731|    0.863|   2.0|     -5.331|    1.0|        0.0377|          0.125|                0.0|      0.195|     0.963| 107.992|              4.0|2016.0|\n",
      "|       141| 141|  0.0|18810.0|      40.0|   237290.0|          0.745|    0.875|   0.0|     -4.231|    1.0|        0.0444|         0.0659|             1.5E-6|      0.366|     0.728|  88.007|              4.0|2016.0|\n",
      "+----------+----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# remove explicit content, and then remove the explicit column\n",
    "df = df.filter(F.col(\"explicit\") == False)\n",
    "df = df.drop(\"explicit\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfdadad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|Unnamed: 0| rank|trend|streams|popularity|duration_ms|af_danceability|af_energy|af_key|af_loudness|af_mode|af_speechiness|af_acousticness|af_instrumentalness|af_liveness|af_valence|af_tempo|af_time_signature|  date|\n",
      "+----------+-----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "|        34| 35.0|  2.0|56170.0|      80.0|   236001.0|          0.666|     0.83|   0.0|     -5.715|    1.0|        0.0751|         0.0123|                0.0|      0.191|     0.702|  113.03|              4.0|2016.0|\n",
      "|        33| 34.0|  0.0|58801.0|      80.0|   225983.0|          0.818|    0.803|   1.0|     -4.282|    1.0|        0.0797|          0.034|                0.0|      0.153|     0.632|  106.97|              4.0|2016.0|\n",
      "|       114|114.0|  1.0|21584.0|      59.0|   206760.0|          0.849|    0.759|   9.0|     -6.232|    0.0|        0.0304|         0.0951|            1.21E-4|      0.127|     0.948| 110.983|              4.0|2017.0|\n",
      "|       163|163.0|  1.0|16865.0|       0.0|   167053.0|          0.731|    0.863|   2.0|     -5.331|    1.0|        0.0377|          0.125|                0.0|      0.195|     0.963| 107.992|              4.0|2016.0|\n",
      "|       141|141.0|  0.0|18810.0|      40.0|   237290.0|          0.745|    0.875|   0.0|     -4.231|    1.0|        0.0444|         0.0659|             1.5E-6|      0.366|     0.728|  88.007|              4.0|2016.0|\n",
      "+----------+-----+-----+-------+----------+-----------+---------------+---------+------+-----------+-------+--------------+---------------+-------------------+-----------+----------+--------+-----------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# convert the rank column to a float\n",
    "df = df.withColumn(\"rank\", F.col(\"rank\").cast(FloatType()))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b12dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.csv(\"numpy_prepped.csv\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
