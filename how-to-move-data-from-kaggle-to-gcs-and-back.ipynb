{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":408,"sourceType":"datasetVersion","datasetId":180},{"sourceId":8129495,"sourceType":"datasetVersion","datasetId":4804894},{"sourceId":13822470,"sourceType":"datasetVersion","datasetId":8802540}],"dockerImageVersionId":29661,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to move data from Kaggle to GCS and back\n* The purpose of this notebook is to demonstrate how to move data from Kaggle into the Google Storage Client\n* We also demonstrate how to move data from the Google Storage Client into a Kaggle notebook\n* Note that this requires enabling Google Cloud Services in the Add-ons menu of the notebook editor.","metadata":{}},{"cell_type":"markdown","source":"**Step 1:** Import Python Modules","metadata":{}},{"cell_type":"markdown","source":"**Step 2:** Import Data from Kaggle\n* Note that you add the data to your kernel by pressing the \"add data\" button in the top right corner of the notebook editor","metadata":{}},{"cell_type":"code","source":"spotify_data = '/kaggle/input/spotify-charts-all-audio-data'\ngcp_key = '/kaggle/input/gcp-key/assignment-4-475110-aecc601938f1.json'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T23:45:04.892440Z","iopub.execute_input":"2025-11-21T23:45:04.892801Z","iopub.status.idle":"2025-11-21T23:45:04.897751Z","shell.execute_reply.started":"2025-11-21T23:45:04.892742Z","shell.execute_reply":"2025-11-21T23:45:04.896692Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Step 3:** Connect to GCS Storage Client and Define Some Helper Functions\n* https://cloud.google.com/storage/docs/","metadata":{}},{"cell_type":"code","source":"from google.cloud import storage\nstorage_client = storage.Client(project='assignment-4-475110')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T23:33:32.075576Z","iopub.execute_input":"2025-11-21T23:33:32.076182Z","iopub.status.idle":"2025-11-21T23:33:33.060928Z","shell.execute_reply.started":"2025-11-21T23:33:32.076109Z","shell.execute_reply":"2025-11-21T23:33:33.059850Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!gcloud auth activate-service-account --key-file=$gcp_key","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T23:45:07.927399Z","iopub.execute_input":"2025-11-21T23:45:07.927771Z","iopub.status.idle":"2025-11-21T23:45:09.798476Z","shell.execute_reply.started":"2025-11-21T23:45:07.927718Z","shell.execute_reply":"2025-11-21T23:45:09.797152Z"}},"outputs":[{"name":"stdout","text":"Activated service account credentials for: [523399915975-compute@developer.gserviceaccount.com]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Replace 'your-bucket-name' with your actual GCS bucket name\n# Replace 'your-dataset-name' with the name of your Kaggle dataset\n# This command copies all files in the input directory to the bucket\n!gsutil -m cp -r $spotify_data gs://your-bucket-name/kaggle_data/ gs://finalprojectmetcs777/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T23:45:12.908414Z","iopub.execute_input":"2025-11-21T23:45:12.908830Z","iopub.status.idle":"2025-11-21T23:51:40.514010Z","shell.execute_reply.started":"2025-11-21T23:45:12.908761Z","shell.execute_reply":"2025-11-21T23:51:40.512445Z"}},"outputs":[{"name":"stdout","text":"AccessDeniedException: 403 523399915975-compute@developer.gserviceaccount.com does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).\nCopying file:///kaggle/input/spotify-charts-all-audio-data/merged_data.csv [Content-Type=text/csv]...\n==> NOTE: You are uploading one or more large file(s), which would run\nsignificantly faster if you enable parallel composite uploads. This\nfeature can be enabled by editing the\n\"parallel_composite_upload_threshold\" value in your .boto\nconfiguration file. However, note that if you do this large files will\nbe uploaded as `composite objects\n<https://cloud.google.com/storage/docs/composite-objects>`_,which\nmeans that any user who downloads such objects will need to have a\ncompiled crcmod installed (see \"gsutil help crcmod\"). This is because\nwithout a compiled crcmod, computing checksums on composite objects is\nso slow that gsutil disables downloads of composite objects.\n\n| [1/1 files][ 25.2 GiB/ 25.2 GiB] 100% Done  65.0 MiB/s ETA 00:00:00           \nOperation completed over 1 objects/25.2 GiB.                                     \nCommandException: 1 file/object could not be transferred.\n","output_type":"stream"}],"execution_count":16}]}