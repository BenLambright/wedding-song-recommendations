{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da569d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lingua import Language, LanguageDetectorBuilder\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caa8df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"LID\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7137868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# because this is the small dataset, I'm making the assumption that all the songs are either in Spanish or English\n",
    "languages = [\n",
    "    Language.ENGLISH,\n",
    "    Language.SPANISH,\n",
    "    Language.ARABIC,\n",
    "    Language.RUSSIAN,\n",
    "    Language.GERMAN,\n",
    "    Language.FRENCH,\n",
    "    Language.ITALIAN,\n",
    "    Language.SWEDISH,\n",
    "    Language.FINNISH,\n",
    "    Language.POLISH,\n",
    "    Language.BULGARIAN,\n",
    "    Language.ROMANIAN,\n",
    "    Language.HUNGARIAN,\n",
    "    Language.GREEK,\n",
    "    Language.TURKISH,\n",
    "    Language.HINDI,\n",
    "    Language.JAPANESE,\n",
    "    Language.KOREAN,\n",
    "    Language.VIETNAMESE,\n",
    "    Language.THAI,\n",
    "    Language.INDONESIAN,\n",
    "    Language.PORTUGUESE,\n",
    "    Language.PUNJABI,\n",
    "    Language.TAMIL,\n",
    "    Language.TELUGU,\n",
    "    Language.TAGALOG,\n",
    "]\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "# example usage\n",
    "language = detector.detect_language_of(\"Cuatro Babys\")\n",
    "print(languages.index(language))  # should print 1 for Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c6c9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+---------------+---------+-----------+--------------+---------------+-------------------+----------+--------+\n",
      "|     _c0|               title|              artist|               album|af_danceability|af_energy|af_loudness|af_speechiness|af_acousticness|af_instrumentalness|af_valence|af_tempo|\n",
      "+--------+--------------------+--------------------+--------------------+---------------+---------+-----------+--------------+---------------+-------------------+----------+--------+\n",
      "|  485174|                   !|            O.S.T.R.|W drodze po szczę...|          0.561|    0.798|     -7.064|          0.32|          0.307|                0.0|      0.14| 140.837|\n",
      "|13259484|\"\"\"Eungenio\"\" Sal...|              Mecano|Descanso Dominica...|          0.381|    0.199|    -15.769|         0.052|          0.925|            6.79E-4|    0.0456| 145.726|\n",
      "|  486856|\"A Lovely Night -...|Ryan Gosling, Emm...|La La Land (Origi...|            0.3|    0.487|     -8.635|        0.0515|          0.342|            0.00295|     0.502| 165.794|\n",
      "| 5438893|\"A Whole New Worl...|gamaliél, Isyana ...|\"A Whole New Worl...|          0.412|    0.357|     -7.409|        0.0318|           0.73|                0.0|     0.273| 120.256|\n",
      "| 8957435|\"Aaina (From \"\"Th...|Arko, Tulsi Kumar...|\"Aaina (From \"\"Th...|          0.509|    0.439|     -6.571|         0.031|          0.513|                0.0|     0.367| 111.298|\n",
      "+--------+--------------------+--------------------+--------------------+---------------+---------+-----------+--------------+---------------+-------------------+----------+--------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"partition1.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# drop rows where the language id is 0, or the title or album is empty\n",
    "df = df.filter(F.col(\"title\").isNotNull())\n",
    "df = df.filter(F.col(\"album\").isNotNull())\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc87a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|               title|               album|language_id|\n",
      "+--------------------+--------------------+-----------+\n",
      "|\"\"\"Eungenio\"\" Sal...|Descanso Dominica...|       -2.0|\n",
      "|\"Aattuthottil - F...|\"Aattuthottil (Fr...|       -2.0|\n",
      "|\"After Met You (F...|\"After Met You (F...|       -2.0|\n",
      "|\"Akala ko - From ...|\"Akala ko (From \"...|       -2.0|\n",
      "|\"Arey Pyaar Kar L...|\"Arey Pyaar Kar L...|       -2.0|\n",
      "|\"Arikil - From \"\"...|\"Arikil (From \"\"A...|       -2.0|\n",
      "|\"Bandeya (feat. A...|\"Bandeya (From \"\"...|       -2.0|\n",
      "|\"Bang Bang - From...|\"Bang Bang (From ...|       -2.0|\n",
      "|\"Check The Timin'...|\"Check The Timin'...|       -2.0|\n",
      "|\"Coconut Mall (Fr...|Mario Kart Wii, T...|       -2.0|\n",
      "|\"Credits - From \"...|La La Land (Origi...|       -2.0|\n",
      "|\"Dil Mein Ho Tum ...|\"Dil Mein Ho Tum ...|       -2.0|\n",
      "|\"Dil Royi Jaye (F...|\"Dil Royi Jaye (F...|       -2.0|\n",
      "|\"Ek Ladki Ko Dekh...|\"Ek Ladki Ko Dekh...|       -2.0|\n",
      "|\"El corrido de Mi...|Coco (Banda Sonor...|       -2.0|\n",
      "|\"Epilogue - From ...|La La Land (Origi...|       -2.0|\n",
      "|\"Ghalat Fehmi - F...|\"Ghalat Fehmi (Fr...|       -2.0|\n",
      "|\"Humnava Mere (Fr...|Romantic Hits By ...|       -2.0|\n",
      "|\"Hurt Me - From \"...|\"Hurt Me (From \"\"...|       -2.0|\n",
      "|\"Kaathalae Kaatha...|\"Kaathalae Kaatha...|       -2.0|\n",
      "|\"Kapitel 1 \"\"Intr...|EXIT RACISM (rass...|       -2.0|\n",
      "|\"La bikina - Insp...|\"La bikina (Inspi...|       -2.0|\n",
      "|\"Laung Laachi Tit...|\"Laung Laachi Tit...|       -2.0|\n",
      "|\"Let It Go - From...|       Demi (Deluxe)|       -2.0|\n",
      "|\"Love You Na Yaar...|\"Love You Na Yaar...|       -2.0|\n",
      "|\"Main Janta Hoon ...|\"Main Janta Hoon ...|       -2.0|\n",
      "|\"Mayilaanjiye - F...|\"Mayilaanjiye (Fr...|       -2.0|\n",
      "|\"Mr. Kupido - Fro...|\"Mr. Kupido (From...|       -2.0|\n",
      "|\"My Life Is Going...|\"My Life Is Going...|       -2.0|\n",
      "|\"Njan Jackson All...|\"Njan Jackson All...|       -2.0|\n",
      "+--------------------+--------------------+-----------+\n",
      "only showing top 30 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\s*[\\(\\[].*?[\\)\\]]\"\n",
    "\n",
    "def detect_language_udf(title, album):\n",
    "    cleaned_title = re.sub(pattern, \"\", title, flags=re.IGNORECASE).strip()\n",
    "    cleaned_album = re.sub(pattern, \"\", album, flags=re.IGNORECASE).strip()\n",
    "    if cleaned_title == cleaned_album:\n",
    "        combined_text = cleaned_title\n",
    "    else:\n",
    "        combined_text = f\"{cleaned_title} {cleaned_album}\"\n",
    "    if not combined_text.strip():\n",
    "        return -1.0  # return -1.0 for empty strings, but we'll remove these afterwards\n",
    "    \n",
    "    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "    language = detector.detect_language_of(combined_text)\n",
    "\n",
    "    confidence_values = detector.compute_language_confidence_values(combined_text)\n",
    "    if confidence_values[0].value < 0.5:\n",
    "        return -2.0  # return -2.0 if confidence is below 50%\n",
    "\n",
    "    return float(languages.index(language))\n",
    "\n",
    "detect_language = F.udf(detect_language_udf, FloatType())\n",
    "\n",
    "df = df.withColumn(\"language_id\", detect_language(F.col(\"title\"), F.col(\"album\")))\n",
    "\n",
    "# filter out language id's where we couldn't detect a language\n",
    "df = df.filter(F.col(\"language_id\") != -1.0)\n",
    "\n",
    "new_df = df.select(\"title\", \"album\", \"language_id\")\n",
    "new_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+-----------+\n",
      "|                                             title|                                             album|                                     combined_text|language_id|\n",
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+-----------+\n",
      "|                      \"\"\"Eungenio\"\" Salvador Dali\"|       Descanso Dominical/Une Femme Avec Une Femme|\"\"\"Eungenio\"\" Salvador Dali\" Descanso Dominical...|       -2.0|\n",
      "|                 \"Aattuthottil - From \"\"Athiran\"\"\"|                 \"Aattuthottil (From \"\"Athiran\"\")\"|  \"Aattuthottil - From \"\"Athiran\"\"\" \"Aattuthottil\"|       -2.0|\n",
      "|          \"After Met You (From \"\"After Met You\"\")\"|          \"After Met You (From \"\"After Met You\"\")\"|                                   \"After Met You\"|       -2.0|\n",
      "|  \"Akala ko - From \"\"Can't Help Falling in Love\"\"\"|  \"Akala ko (From \"\"Can't Help Falling in Love\"\")\"|\"Akala ko - From \"\"Can't Help Falling in Love\"\"...|       -2.0|\n",
      "|\"Arey Pyaar Kar Le (From \"\"Shubh Mangal Zyada S...|\"Arey Pyaar Kar Le (From \"\"Shubh Mangal Zyada S...|                               \"Arey Pyaar Kar Le\"|       -2.0|\n",
      "|                        \"Arikil - From \"\"Arikil\"\"\"|                        \"Arikil (From \"\"Arikil\"\")\"|               \"Arikil - From \"\"Arikil\"\"\" \"Arikil\"|       -2.0|\n",
      "|\"Bandeya (feat. Arijit Singh) - From \"\"Dil Juun...|                 \"Bandeya (From \"\"Dil Juunglee\"\")\"|       \"Bandeya - From \"\"Dil Juunglee\"\"\" \"Bandeya\"|       -2.0|\n",
      "|         \"Bang Bang - From \"\"Gauthamante Radham\"\"\"|         \"Bang Bang (From \"\"Gauthamante Radham\"\")\"|\"Bang Bang - From \"\"Gauthamante Radham\"\"\" \"Bang...|       -2.0|\n",
      "|\"Check The Timin' - Fra TV-Programmet \"\"The Voi...|\"Check The Timin' (Fra TV-Programmet \"\"The Voic...|\"Check The Timin' - Fra TV-Programmet \"\"The Voi...|       -2.0|\n",
      "|          \"Coconut Mall (From \"\"Mario Kart Wii\"\")\"|                        Mario Kart Wii, The Themes|         \"Coconut Mall\" Mario Kart Wii, The Themes|       -2.0|\n",
      "|             \"Credits - From \"\"La La Land\"\" Score\"|        La La Land (Original Motion Picture Score)|  \"Credits - From \"\"La La Land\"\" Score\" La La Land|       -2.0|\n",
      "|          \"Dil Mein Ho Tum (From \"\"Cheat India\"\")\"|          \"Dil Mein Ho Tum (From \"\"Cheat India\"\")\"|                                 \"Dil Mein Ho Tum\"|       -2.0|\n",
      "|         \"Dil Royi Jaye (From \"\"De De Pyaar De\"\")\"|         \"Dil Royi Jaye (From \"\"De De Pyaar De\"\")\"|                                   \"Dil Royi Jaye\"|       -2.0|\n",
      "|\"Ek Ladki Ko Dekha Toh Aisa Laga (From \"\"Ek Lad...|\"Ek Ladki Ko Dekha Toh Aisa Laga (From \"\"Ek Lad...|\"Ek Ladki Ko Dekha Toh Aisa Laga\" \"Ek Ladki Ko ...|       -2.0|\n",
      "|\"El corrido de Miguel Rivera - Inspirado en \"\"C...|           Coco (Banda Sonora Original en Español)|\"El corrido de Miguel Rivera - Inspirado en \"\"C...|       -2.0|\n",
      "|       \"Epilogue - From \"\"La La Land\"\" Soundtrack\"|        La La Land (Original Motion Picture Score)|\"Epilogue - From \"\"La La Land\"\" Soundtrack\" La ...|       -2.0|\n",
      "|               \"Ghalat Fehmi - From \"\"Superstar\"\"\"|               \"Ghalat Fehmi (From \"\"Superstar\"\")\"|\"Ghalat Fehmi - From \"\"Superstar\"\"\" \"Ghalat Fehmi\"|       -2.0|\n",
      "|            \"Humnava Mere (From \"\"Humnava Mere\"\")\"|                   Romantic Hits By Jubin Nautiyal|    \"Humnava Mere\" Romantic Hits By Jubin Nautiyal|       -2.0|\n",
      "|                     \"Hurt Me - From \"\"Songland\"\"\"|                     \"Hurt Me (From \"\"Songland\"\")\"|           \"Hurt Me - From \"\"Songland\"\"\" \"Hurt Me\"|       -2.0|\n",
      "|               \"Kaathalae Kaathalae - From \"\"96\"\"\"|               \"Kaathalae Kaathalae (From \"\"96\"\")\"|\"Kaathalae Kaathalae - From \"\"96\"\"\" \"Kaathalae ...|       -2.0|\n",
      "|               \"Kapitel 1 \"\"Intro\"\" - EXIT RACISM\"|     EXIT RACISM (rassismuskritisch denken lernen)|   \"Kapitel 1 \"\"Intro\"\" - EXIT RACISM\" EXIT RACISM|       -2.0|\n",
      "|               \"La bikina - Inspirado en \"\"COCO\"\"\"|               \"La bikina (Inspirado en \"\"COCO\"\")\"|   \"La bikina - Inspirado en \"\"COCO\"\"\" \"La bikina\"|       -2.0|\n",
      "|\"Laung Laachi Title Track (From \"\"Laung Laachi\"\")\"|\"Laung Laachi Title Track (From \"\"Laung Laachi\"\")\"|                        \"Laung Laachi Title Track\"|       -2.0|\n",
      "|      \"Let It Go - From \"\"Frozen / Single Version\"|                                     Demi (Deluxe)| \"Let It Go - From \"\"Frozen / Single Version\" Demi|       -2.0|\n",
      "|    \"Love You Na Yaar - From \"\"Love You Na Yaar\"\"\"|    \"Love You Na Yaar (From \"\"Love You Na Yaar\"\")\"|\"Love You Na Yaar - From \"\"Love You Na Yaar\"\"\" ...|       -2.0|\n",
      "|             \"Main Janta Hoon (From \"\"The Body\"\")\"|             \"Main Janta Hoon (From \"\"The Body\"\")\"|                                 \"Main Janta Hoon\"|       -2.0|\n",
      "|   \"Mayilaanjiye - From \"\"Sivappu Manjal Pachai\"\"\"|   \"Mayilaanjiye (From \"\"Sivappu Manjal Pachai\"\")\"|\"Mayilaanjiye - From \"\"Sivappu Manjal Pachai\"\"\"...|       -2.0|\n",
      "|       \"Mr. Kupido - From \"\"A Love So Beautiful\"\"\"|       \"Mr. Kupido (From \"\"A Love So Beautiful\"\")\"|\"Mr. Kupido - From \"\"A Love So Beautiful\"\"\" \"Mr...|       -2.0|\n",
      "| \"My Life Is Going On - From \"\"La casa de papel\"\"\"| \"My Life Is Going On (From \"\"La casa de papel\"\")\"|\"My Life Is Going On - From \"\"La casa de papel\"...|       -2.0|\n",
      "|           \"Njan Jackson Allada - From \"\"Ambili\"\"\"|           \"Njan Jackson Allada (From \"\"Ambili\"\")\"|\"Njan Jackson Allada - From \"\"Ambili\"\"\" \"Njan J...|       -2.0|\n",
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+-----------+\n",
      "only showing top 30 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.types import FloatType, StringType\n",
    "# import pyspark.sql.functions as F\n",
    "# import re\n",
    "\n",
    "# pattern = r\"\\s*[\\(\\[].*?[\\)\\]]\"\n",
    "\n",
    "# # UDF 1: preprocess title + album into combined text\n",
    "# def preprocess_text_udf(title, album):\n",
    "#     cleaned_title = re.sub(pattern, \"\", title or \"\", flags=re.IGNORECASE).strip()\n",
    "#     cleaned_album = re.sub(pattern, \"\", album or \"\", flags=re.IGNORECASE).strip()\n",
    "#     if cleaned_title == cleaned_album:\n",
    "#         combined_text = cleaned_title\n",
    "#     else:\n",
    "#         combined_text = f\"{cleaned_title} {cleaned_album}\"\n",
    "#     return combined_text\n",
    "\n",
    "# preprocess_text = F.udf(preprocess_text_udf, StringType())\n",
    "\n",
    "# # Apply preprocessing UDF\n",
    "# df = df.withColumn(\"combined_text\", preprocess_text(F.col(\"title\"), F.col(\"album\")))\n",
    "\n",
    "# # UDF 2: detect language from combined text\n",
    "# def detect_language_index_udf(combined_text):\n",
    "#     if not combined_text.strip():\n",
    "#         return -1.0  # empty string\n",
    "\n",
    "#     detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "#     language = detector.detect_language_of(combined_text)\n",
    "#     confidence_values = detector.compute_language_confidence_values(combined_text)\n",
    "#     if confidence_values[0].value < 0.5:\n",
    "#         return -2.0  # low confidence\n",
    "\n",
    "#     return float(languages.index(language))\n",
    "\n",
    "# detect_language_index = F.udf(detect_language_index_udf, FloatType())\n",
    "\n",
    "# # Apply language detection UDF\n",
    "# df = df.withColumn(\"language_id\", detect_language_index(F.col(\"combined_text\")))\n",
    "\n",
    "# # Filter out rows where detection failed\n",
    "# df = df.filter(F.col(\"language_id\") != -1.0)\n",
    "\n",
    "# # View resulting DataFrame with both combined text and language index\n",
    "# new_df = df.select(\"title\", \"album\", \"combined_text\", \"language_id\")\n",
    "# new_df.show(30, truncate=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d59b1d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: \"Aaina\"\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "test_title = \"\\\"Aaina (From \\\"\\\"The Body\\\"\\\")\\\"\"\n",
    "test_album = \"\\\"Aaina (From \\\"\\\"The Body\\\"\\\")\\\"\"\n",
    "cleaned_test_title = re.sub(pattern, \"\", test_title, flags=re.IGNORECASE).strip()\n",
    "cleaned_test_album = re.sub(pattern, \"\", test_album, flags=re.IGNORECASE).strip()\n",
    "if cleaned_test_album == cleaned_test_album:\n",
    "    combined_text = cleaned_test_title\n",
    "else:\n",
    "    combined_text = f\"{cleaned_test_title} {cleaned_test_album}\"\n",
    "print(f\"Cleaned: {combined_text}\")\n",
    "print(len(combined_text.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7107b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.write.csv(\"subset_with_language_id.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGALOG: 0.22\n",
      "SPANISH: 0.18\n",
      "PORTUGUESE: 0.14\n",
      "INDONESIAN: 0.08\n",
      "FRENCH: 0.08\n",
      "ROMANIAN: 0.06\n",
      "POLISH: 0.05\n",
      "FINNISH: 0.04\n",
      "ITALIAN: 0.04\n",
      "ENGLISH: 0.03\n",
      "GERMAN: 0.02\n",
      "SWEDISH: 0.02\n",
      "HUNGARIAN: 0.02\n",
      "TURKISH: 0.01\n",
      "VIETNAMESE: 0.00\n",
      "ARABIC: 0.00\n",
      "BULGARIAN: 0.00\n",
      "GREEK: 0.00\n",
      "HINDI: 0.00\n",
      "JAPANESE: 0.00\n",
      "KOREAN: 0.00\n",
      "PUNJABI: 0.00\n",
      "RUSSIAN: 0.00\n",
      "TAMIL: 0.00\n",
      "TELUGU: 0.00\n",
      "THAI: 0.00\n",
      "0.22155691676525158\n"
     ]
    }
   ],
   "source": [
    "confidence_values = detector.compute_language_confidence_values(\"La bikina - Inspirado en \\\"COCO\\\" La bikina\")\n",
    "for confidence in confidence_values:\n",
    "    print(f\"{confidence.language.name}: {confidence.value:.2f}\")\n",
    "\n",
    "print(confidence_values[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c3d4012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "print(detect(\"Arey Pyaar Kar Le\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2250e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "lang_list = [\n",
    "    \"af\", \"ar\", \"bg\", \"bn\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\",\n",
    "    \"en\", \"es\", \"et\", \"fa\", \"fi\", \"fr\", \"gu\", \"he\", \"hi\", \"hr\",\n",
    "    \"hu\", \"id\", \"it\", \"ja\", \"kn\", \"ko\", \"lt\", \"lv\", \"mk\", \"ml\",\n",
    "    \"mr\", \"ne\", \"nl\", \"no\", \"pa\", \"pl\", \"pt\", \"ro\", \"ru\", \"sk\",\n",
    "    \"sl\", \"so\", \"sq\", \"sv\", \"sw\", \"ta\", \"te\", \"th\", \"tl\", \"tr\",\n",
    "    \"uk\", \"ur\", \"vi\", \"zh-cn\", \"zh-tw\"\n",
    "]\n",
    "print(len(lang_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
